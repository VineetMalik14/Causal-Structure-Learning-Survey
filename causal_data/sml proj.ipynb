{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "import castle\n",
    "from castle.common import GraphDAG\n",
    "from castle.metrics import MetricsDAG\n",
    "from castle.datasets import IIDSimulation, DAG\n",
    "# from castle.algorithms import PC, DirectLiNGAM, ICALiNGAM, GES, CORL, Notears\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(action='ignore', category=DeprecationWarning, message=\"`np.int` is a deprecated alias for the builtin `int`\")\n",
    "filterwarnings(action='ignore', category=DeprecationWarning, message=\"`np.float` is a deprecated alias for the builtin `float`\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_matrix(file_path):\n",
    "    return  pd.read_csv(file_path).to_numpy()\n",
    "\n",
    "def save_matrix(data, file_path):\n",
    "    pd.DataFrame(data).to_csv(file_path, index=False)\n",
    "\n",
    "FOLDER_PATH  = \"./causal_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  70\n",
      "sample_size =  1000\n",
      "here\n"
     ]
    }
   ],
   "source": [
    "for n in [70]:#[10,40,70,100]:\n",
    "    p = pow(n,-0.7)\n",
    "    print(\"n = \",n)\n",
    "    n_edges = n*n*p/2\n",
    "    for sample_size in [1000]:#[1000, 4000, 7000, 10000]:\n",
    "        print(\"sample_size = \",sample_size)\n",
    "        for seed in range(1):\n",
    "            print(\"here\")\n",
    "            weighted_random_dag = DAG.erdos_renyi(n_nodes=n, n_edges=n_edges,\n",
    "                                      weight_range=(0.5, 2.0), seed=seed)\n",
    "            dataset = IIDSimulation(W=weighted_random_dag, n=sample_size, method='linear',\n",
    "                        sem_type='gauss')\n",
    "            true_causal_matrix, X = dataset.B, dataset.X\n",
    "            actual_num_edge=np.count_nonzero(np.array(weighted_random_dag))\n",
    "#             file_name = \"_{}_{}_{}.csv\".format(n,sample_size, seed) \n",
    "            file_name = \"_{}_{}.csv\".format(n,sample_size,) \n",
    "            save_matrix(true_causal_matrix, os.path.join(FOLDER_PATH, \"causal\"+file_name))\n",
    "            save_matrix(X,  os.path.join(FOLDER_PATH, \"sim_data\"+file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 00:52:02,367 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:196] - INFO: [start]: n=1000, d=10, iter_=100, h_=1e-08, rho_=1e+16\n",
      "2022-12-03 00:52:02,529 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 0] h=1.707e-01, loss=7.613, rho=1.0e+00\n",
      "2022-12-03 00:52:02,618 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 1] h=1.365e-01, loss=5.051, rho=1.0e+00\n",
      "2022-12-03 00:52:02,743 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 1] h=7.413e-02, loss=5.182, rho=1.0e+01\n",
      "2022-12-03 00:52:02,935 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 1] h=2.743e-02, loss=6.492, rho=1.0e+02\n",
      "2022-12-03 00:52:03,043 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 2] h=1.735e-02, loss=5.242, rho=1.0e+02\n",
      "2022-12-03 00:52:03,137 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 2] h=7.159e-03, loss=5.581, rho=1.0e+03\n",
      "2022-12-03 00:52:03,340 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 2] h=1.830e-03, loss=8.968, rho=1.0e+04\n",
      "2022-12-03 00:52:03,499 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 3] h=9.212e-04, loss=5.361, rho=1.0e+04\n",
      "2022-12-03 00:52:03,720 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 3] h=3.199e-04, loss=5.511, rho=1.0e+05\n",
      "2022-12-03 00:52:03,912 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 4] h=1.823e-04, loss=5.373, rho=1.0e+05\n",
      "2022-12-03 00:52:03,964 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 4] h=6.141e-05, loss=5.419, rho=1.0e+06\n",
      "2022-12-03 00:52:04,220 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 5] h=4.065e-05, loss=5.381, rho=1.0e+06\n",
      "2022-12-03 00:52:04,336 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 5] h=1.425e-05, loss=5.398, rho=1.0e+07\n",
      "2022-12-03 00:52:04,622 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 6] h=8.598e-06, loss=5.385, rho=1.0e+07\n",
      "2022-12-03 00:52:04,925 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 6] h=3.139e-06, loss=5.394, rho=1.0e+08\n",
      "2022-12-03 00:52:05,061 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 7] h=1.822e-06, loss=5.385, rho=1.0e+08\n",
      "2022-12-03 00:52:05,224 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 7] h=6.748e-07, loss=5.389, rho=1.0e+09\n",
      "2022-12-03 00:52:05,357 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 8] h=3.913e-07, loss=5.386, rho=1.0e+09\n",
      "2022-12-03 00:52:05,502 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 8] h=1.455e-07, loss=5.388, rho=1.0e+10\n",
      "2022-12-03 00:52:05,637 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 9] h=8.418e-08, loss=5.386, rho=1.0e+10\n",
      "2022-12-03 00:52:05,814 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 9] h=3.134e-08, loss=5.387, rho=1.0e+11\n",
      "2022-12-03 00:52:05,936 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 10] h=1.807e-08, loss=5.386, rho=1.0e+11\n",
      "2022-12-03 00:52:06,065 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 10] h=6.750e-09, loss=5.387, rho=1.0e+12\n",
      "2022-12-03 00:52:06,067 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:222] - INFO: FINISHED\n",
      "2022-12-03 00:52:06,184 - /home/aarushi/anaconda3/lib/python3.7/site-packages/numexpr/utils.py[line:141] - INFO: NumExpr defaulting to 4 threads.\n",
      "2022-12-03 00:52:07,078 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:196] - INFO: [start]: n=1000, d=70, iter_=100, h_=1e-08, rho_=1e+16\n",
      "2022-12-03 00:52:36,444 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 0] h=1.534e+00, loss=8627.295, rho=1.0e+00\n",
      "2022-12-03 00:52:57,853 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 1] h=1.004e+00, loss=39.057, rho=1.0e+00\n",
      "2022-12-03 00:53:21,709 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 1] h=4.362e-01, loss=49.652, rho=1.0e+01\n",
      "2022-12-03 00:53:50,440 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 1] h=1.394e-01, loss=155.594, rho=1.0e+02\n",
      "2022-12-03 00:54:17,717 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 2] h=8.245e-02, loss=44.573, rho=1.0e+02\n",
      "2022-12-03 00:54:50,247 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 2] h=3.394e-02, loss=53.314, rho=1.0e+03\n",
      "2022-12-03 00:55:08,810 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 3] h=2.168e-02, loss=46.383, rho=1.0e+03\n",
      "2022-12-03 00:55:31,979 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 3] h=9.119e-03, loss=51.567, rho=1.0e+04\n",
      "2022-12-03 00:55:57,361 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 3] h=2.988e-03, loss=103.410, rho=1.0e+05\n",
      "2022-12-03 00:56:13,441 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 4] h=1.867e-03, loss=48.817, rho=1.0e+05\n",
      "2022-12-03 00:56:42,915 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 4] h=8.234e-04, loss=52.835, rho=1.0e+06\n",
      "2022-12-03 00:57:27,492 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 4] h=2.681e-04, loss=93.014, rho=1.0e+07\n",
      "2022-12-03 00:58:14,058 - /home/aarushi/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py[line:208] - INFO: [iter 5] h=1.478e-04, loss=50.772, rho=1.0e+07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b7c8f4fd51c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#         print(algo_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mpc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malgo_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# plot predict_dag and true_dag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, data, columns, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m                                     \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                                     \u001b[0mh_tol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_tol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                                     rho_max=self.rho_max)\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mcausal_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_est\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         self.weight_causal_matrix = Tensor(W_est,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py\u001b[0m in \u001b[0;36mnotears_linear\u001b[0;34m(self, X, lambda1, loss_type, max_iter, h_tol, rho_max)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mrho\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mrho_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 sol = sopt.minimize(_func, w_est, method='L-BFGS-B', \n\u001b[0;32m--> 202\u001b[0;31m                                     jac=True, bounds=bnds)\n\u001b[0m\u001b[1;32m    203\u001b[0m                 \u001b[0mw_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mh_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 624\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py\u001b[0m in \u001b[0;36m_func\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \"\"\"\n\u001b[1;32m    178\u001b[0m             \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_adj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrho\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/castle/algorithms/gradient/notears/linear.py\u001b[0m in \u001b[0;36m_loss\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0mG_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mloss_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'logistic'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogaddexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/castle/common/base.py\u001b[0m in \u001b[0;36m__array_finalize__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# algorithms = {\"PC\":PC(), \"DirectLiNGAM\": DirectLiNGAM(),\"ICALiNGAM\": ICALiNGAM(max_iter=10000) }#max_iter=1000000\n",
    "algorithms = {\"Notears\":Notears(),  \"GES\": GES(),  }\n",
    "# __all__ = ['ANMNonlinear', 'GES', 'TTPM', 'DirectLiNGAM', 'ICALiNGAM', 'PC', 'Notears', 'DAG_GNN',\n",
    "#            'NotearsLowRank', 'RL', 'CORL', 'GraNDAG', 'NotearsNonlinear', 'GOLEM', 'MCSL', 'GAE']\n",
    "\n",
    "# data simulation, simulate true causal dag and train_data.\n",
    "# structure learning\n",
    "metrics = ['fdr', 'tpr', 'fpr', 'shd', 'nnz', 'precision', 'recall', 'F1', 'gscore']\n",
    "file_names = os.listdir(FOLDER_PATH)\n",
    "file_names = [x for x in file_names if x[:6]==\"causal\"]\n",
    "for algo_name in algorithms:\n",
    "    results = []\n",
    "    t=time.time()\n",
    "    i=0\n",
    "    for file_name in file_names:\n",
    "#     file_name = \"causal_10_1000_0_3.csv\"\n",
    "#     file_name = \"causal_10_10000_0_3.csv\"\n",
    "#     print(file_name)\n",
    "        causal_graph = read_matrix(os.path.join(FOLDER_PATH, file_name))\n",
    "        sim_data = read_matrix(os.path.join(FOLDER_PATH, file_name.replace(\"causal\", \"sim_data\")))\n",
    "        _,n,sample_size, seed,actual_num_edge = file_name[:-4].split(\"_\")\n",
    "        n,sample_size, seed,actual_num_edge = int(n), int(sample_size), int(seed), int(actual_num_edge)\n",
    "        if seed!=0 or n==100 or sample_size==10000:\n",
    "            continue\n",
    "    #         print(algo_name)\n",
    "        pc = algorithms[algo_name]\n",
    "        pc.learn(sim_data)\n",
    "\n",
    "        # plot predict_dag and true_dag\n",
    "#         GraphDAG(pc.causal_matrix, causal_graph, 'result')\n",
    "\n",
    "        # calculate metrics\n",
    "        mt = MetricsDAG(pc.causal_matrix, causal_graph)\n",
    "        result = [n,sample_size, seed,actual_num_edge, algo_name] + [mt.metrics[x] for x in metrics]\n",
    "        results.append(result) \n",
    "        i+=1\n",
    "        if i%3==0:\n",
    "            print(algo_name,i)\n",
    "            print(t-time.time())\n",
    "#         print(algo_name)\n",
    "#         break\n",
    "#     break\n",
    "    pd.DataFrame(results, columns = [\"n\", \"samples\", \"seed\", \"num_edges\", \"algo\"]+metrics).to_csv(\"results_\"+algo_name+\".csv\", index=False)\n",
    "#     i+=1\n",
    "#     print(i, file_name)\n",
    "# results = pd.DataFrame(results, columns = [\"n\", \"samples\", \"seed\", \"num_edges\", \"algo\"]+metrics)\n",
    "# results.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.13 (main, Aug 25 2022, 23:26:10) \n",
      "[GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.13 (main, Aug 25 2022, 23:26:10) \n",
      "[GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import castle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'castle' from '/home/aarushi/.local/lib/python3.7/site-packages/castle/__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "castle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
